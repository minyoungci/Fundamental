{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = torch.zeros(50, 512)\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 512])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 256])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe[:, 0::2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsqueeze()\n",
    "\n",
    "Unsqueeze() 함수는 PyTorch 텐서에 새로운 차원을 추가하는 메서드입니다. 이 함수는 지정된 위치에 크기가 1인 새 차원을 삽입합니다. 이는 텐서의 형상을 변경하는 데 유용하며, 특히 브로드캐스팅이나 특정 연산에 필요한 차원을 추가할 때 자주 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor a:\n",
      "tensor([1, 2, 3, 4])\n",
      "Shape of a: torch.Size([4])\n",
      "\n",
      "After a.unsqueeze(0):\n",
      "tensor([[1, 2, 3, 4]])\n",
      "Shape of b: torch.Size([1, 4])\n",
      "\n",
      "After a.unsqueeze(1):\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "Shape of c: torch.Size([4, 1])\n",
      "\n",
      "Original 2D tensor d:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Shape of d: torch.Size([2, 3])\n",
      "\n",
      "After d.unsqueeze(0):\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "Shape of e: torch.Size([1, 2, 3])\n",
      "\n",
      "After d.unsqueeze(2):\n",
      "tensor([[[1],\n",
      "         [2],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [5],\n",
      "         [6]]])\n",
      "Shape of f: torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1차원 텐서 생성\n",
    "a = torch.tensor([1, 2, 3, 4])\n",
    "print(\"Original tensor a:\")\n",
    "print(a)\n",
    "print(\"Shape of a:\", a.shape)\n",
    "\n",
    "# 0번 인덱스에 차원 추가\n",
    "b = a.unsqueeze(0)\n",
    "print(\"\\nAfter a.unsqueeze(0):\")\n",
    "print(b)\n",
    "print(\"Shape of b:\", b.shape)\n",
    "\n",
    "# 1번 인덱스에 차원 추가\n",
    "c = a.unsqueeze(1)\n",
    "print(\"\\nAfter a.unsqueeze(1):\")\n",
    "print(c)\n",
    "print(\"Shape of c:\", c.shape)\n",
    "\n",
    "# 2차원 텐서 생성\n",
    "d = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"\\nOriginal 2D tensor d:\")\n",
    "print(d)\n",
    "print(\"Shape of d:\", d.shape)\n",
    "\n",
    "# 0번 인덱스에 차원 추가\n",
    "e = d.unsqueeze(0)\n",
    "print(\"\\nAfter d.unsqueeze(0):\")\n",
    "print(e)\n",
    "print(\"Shape of e:\", e.shape)\n",
    "\n",
    "# 2번 인덱스에 차원 추가\n",
    "f = d.unsqueeze(2)\n",
    "print(\"\\nAfter d.unsqueeze(2):\")\n",
    "print(f)\n",
    "print(\"Shape of f:\", f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(d.shape)  # torch.Size([2, 3])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1],\n",
       "         [2],\n",
       "         [3]],\n",
       "\n",
       "        [[4],\n",
       "         [5],\n",
       "         [6]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View()\n",
    "\n",
    "- 텐서의 형상을 변경\n",
    "\n",
    "- 전체 요소의 수는 바뀌지 않는다.\n",
    "\n",
    "- 메모리 레이아웃을 변경하지 않고 텐서를 재해석합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor x: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "# 3x4 텐서 생성 \n",
    "\n",
    "x = torch.tensor([[1, 2, 3, 4],\n",
    "                  [5, 6, 7, 8],\n",
    "                  [9, 10, 11, 12]]) \n",
    "\n",
    "print(\"Original tensor x:\" , x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After x.view(2, 6): torch.Size([2, 6])\n",
      "tensor([[ 1,  2,  3,  4,  5,  6],\n",
      "        [ 7,  8,  9, 10, 11, 12]])\n",
      "\n",
      "Original tensor x: torch.Size([3, 4])\n",
      "New tensor y: torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "y = x.view(2, 6)\n",
    "\n",
    "print(\"\\nAfter x.view(2, 6):\", y.shape) \n",
    "print(y)\n",
    "print(\"\\nOriginal tensor x:\" , x.shape)\n",
    "print(\"New tensor y:\" , y.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After view(-1):\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n",
      "New shape: torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "# 1차원으로 펼치기\n",
    "z = x.view(-1)\n",
    "print(\"After view(-1):\")\n",
    "print(z)\n",
    "print(\"New shape:\", z.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transpose()\n",
    "\n",
    "- 지정된 두 차원의 순서를 바꿉니다.\n",
    "\n",
    "- 메모리 레이아웃을 변경할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([2, 3, 4])\n",
      "After transpose(0, 1):\n",
      "tensor([[[ 1,  2,  3,  4],\n",
      "         [13, 14, 15, 16]],\n",
      "\n",
      "        [[ 5,  6,  7,  8],\n",
      "         [17, 18, 19, 20]],\n",
      "\n",
      "        [[ 9, 10, 11, 12],\n",
      "         [21, 22, 23, 24]]])\n",
      "New shape: torch.Size([3, 2, 4])\n",
      "After transpose(1, 2):\n",
      "tensor([[[ 1,  5,  9],\n",
      "         [ 2,  6, 10],\n",
      "         [ 3,  7, 11],\n",
      "         [ 4,  8, 12]],\n",
      "\n",
      "        [[13, 17, 21],\n",
      "         [14, 18, 22],\n",
      "         [15, 19, 23],\n",
      "         [16, 20, 24]]])\n",
      "New shape: torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 2x3x4 텐서 생성\n",
    "x = torch.tensor([[[1, 2, 3, 4],\n",
    "                   [5, 6, 7, 8],\n",
    "                   [9, 10, 11, 12]],\n",
    "                  [[13, 14, 15, 16],\n",
    "                   [17, 18, 19, 20],\n",
    "                   [21, 22, 23, 24]]])\n",
    "\n",
    "print(\"Original shape:\", x.shape)  # 출력: torch.Size([2, 3, 4])\n",
    "\n",
    "# 첫 번째와 두 번째 차원 교환\n",
    "y = x.transpose(0, 1)\n",
    "print(\"After transpose(0, 1):\")\n",
    "print(y)\n",
    "print(\"New shape:\", y.shape)  # 출력: torch.Size([3, 2, 4])\n",
    "\n",
    "# 두 번째와 세 번째 차원 교환\n",
    "z = x.transpose(1, 2)\n",
    "print(\"After transpose(1, 2):\")\n",
    "print(z)\n",
    "print(\"New shape:\", z.shape)  # 출력: torch.Size([2, 4, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MHA 에서의 사용 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After view: torch.Size([32, 10, 8, 64])\n",
      "After transpose: torch.Size([32, 8, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "# 가정: batch_size=32, seq_len=10, d_model=512, num_heads=8\n",
    "query = torch.randn(32, 10, 512)\n",
    "d_k = 512 // 8  # 64\n",
    "\n",
    "# view를 사용한 reshape\n",
    "reshaped = query.view(32, 10, 8, 64)\n",
    "print(\"After view:\", reshaped.shape)  # 출력: torch.Size([32, 10, 8, 64])\n",
    "\n",
    "# transpose를 사용한 차원 교환\n",
    "transposed = reshaped.transpose(1, 2)\n",
    "print(\"After transpose:\", transposed.shape)  # 출력: torch.Size([32, 8, 10, 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# einops의 rearrange()\n",
    "\n",
    "기본 구문 : rearrange(tensor, pattern, **axes_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'h w -> w h'는 높이(h)와 너비(w)의 순서를 바꿉니다.\n",
    "\n",
    "\n",
    "이는 transpose(0, 1)와 동일한 효과를 가집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Rearranged:\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from einops import rearrange\n",
    "\n",
    "# 2x3 텐서 생성\n",
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "\n",
    "# 'h w -> w h' 패턴으로 변환\n",
    "y = rearrange(x, 'h w -> w h')\n",
    "\n",
    "print(\"Original:\")\n",
    "print(x)\n",
    "print(\"Rearranged:\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([2, 4, 6])\n",
      "Rearranged shape: torch.Size([2, 3, 4, 2])\n",
      "\n",
      "Original first batch:\n",
      "tensor([[ 0.4128, -1.6735, -0.7718, -0.1332, -1.2515, -0.9798],\n",
      "        [ 0.1550,  0.0801, -0.4636,  0.4807, -0.8876, -0.1907],\n",
      "        [ 0.7108,  0.6153, -1.6800,  0.6584,  0.4997,  1.6443],\n",
      "        [ 1.3176,  0.3500, -2.1003, -1.1443,  0.5477,  0.7834]])\n",
      "\n",
      "Rearranged first batch:\n",
      "tensor([[[ 0.4128, -1.6735],\n",
      "         [ 0.1550,  0.0801],\n",
      "         [ 0.7108,  0.6153],\n",
      "         [ 1.3176,  0.3500]],\n",
      "\n",
      "        [[-0.7718, -0.1332],\n",
      "         [-0.4636,  0.4807],\n",
      "         [-1.6800,  0.6584],\n",
      "         [-2.1003, -1.1443]],\n",
      "\n",
      "        [[-1.2515, -0.9798],\n",
      "         [-0.8876, -0.1907],\n",
      "         [ 0.4997,  1.6443],\n",
      "         [ 0.5477,  0.7834]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from einops import rearrange\n",
    "\n",
    "# 입력 텐서 생성 (batch_size=2, seq_len=4, d_model=6)\n",
    "x = torch.randn(2, 4, 6)\n",
    "\n",
    "# Multi-Head Attention을 위한 변환 (3개의 헤드 사용)\n",
    "y = rearrange(x, 'b s (h d) -> b h s d', h=3)\n",
    "\n",
    "print(\"Original shape:\", x.shape)\n",
    "print(\"Rearranged shape:\", y.shape)\n",
    "print(\"\\nOriginal first batch:\")\n",
    "print(x[0])\n",
    "print(\"\\nRearranged first batch:\")\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4128, -1.6735, -0.7718, -0.1332, -1.2515, -0.9798],\n",
       "          [ 0.1550,  0.0801, -0.4636,  0.4807, -0.8876, -0.1907],\n",
       "          [ 0.7108,  0.6153, -1.6800,  0.6584,  0.4997,  1.6443],\n",
       "          [ 1.3176,  0.3500, -2.1003, -1.1443,  0.5477,  0.7834]],\n",
       "\n",
       "         [[-0.2334,  0.0522,  0.0320, -0.6319, -0.7109,  0.1886],\n",
       "          [ 1.3602, -1.3268,  0.2144, -0.7237,  1.0461, -0.4960],\n",
       "          [ 0.3507,  0.0525,  0.5012, -0.5611, -0.0548, -0.6728],\n",
       "          [ 0.9347,  1.3708, -0.9378,  1.0910, -0.3654, -0.5567]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 차원 축소\n",
    "z = rearrange(x, 'b s d -> b (s d)')\n",
    "\n",
    "# 새 차원 추가\n",
    "w = rearrange(x, 'b s d -> b s d 1')\n",
    "\n",
    "# 반복\n",
    "v = rearrange(x, '(b rep) s d -> b rep s d', rep=2)\n",
    "\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
